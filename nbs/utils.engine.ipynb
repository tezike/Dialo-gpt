{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp utils.engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import time\n",
    "import timeit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from abc import ABC\n",
    "from fastprogress.fastprogress import master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Fitter(ABC):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def log(self):\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def validate(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DialoGPTFitter(Fitter):\n",
    "    def __init__(self, model, dataloaders, optimizer, device, log_file='training_log.txt',scheduler=None):\n",
    "        self.model = model\n",
    "        self.train_dl, self.valid_dl = dataloaders[0], dataloaders[1]\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        if not os.path.exists(os.path.join('..', 'outputs')): os.makedirs(os.path.join('..', 'outputs'))\n",
    "        if os.path.exists(os.path.join('..', 'outputs', f'{log_file}')): \n",
    "            os.remove(os.path.join('..', 'outputs', f'{log_file}'))\n",
    "        self.log_file = os.path.join('..', 'outputs', f'{log_file}')\n",
    "        self.device = device\n",
    "        \n",
    "    def fit(self, epochs, return_metric=False, \n",
    "            monitor='epoch train_loss valid_loss time', \n",
    "            model_path=os.path.join('..', 'weights', 'model.pth'), show_graph=True):\n",
    "        self.model_path = model_path\n",
    "        self.log(f'{time.ctime()}')\n",
    "        self.log(f'Using device: {self.device}')\n",
    "        mb = master_bar(range(1, epochs+1)) #MAJOR\n",
    "        mb.write(monitor.split(),table=True)\n",
    "        \n",
    "        model = self.model.to(self.device)\n",
    "        optimizer = self.optimizer\n",
    "        scheduler = self.scheduler\n",
    "        best_metric = -np.inf\n",
    "        train_loss_list, valid_loss_list = [], []\n",
    "        \n",
    "        for i_, epoch in enumerate(mb):\n",
    "            epoch_start = timeit.default_timer()\n",
    "            start = time.time()\n",
    "            self.log('-'*50)\n",
    "            self.log(f'Running Epoch #{epoch} {\"ðŸ”¥\"*epoch}')\n",
    "            self.log(f'{\"-\"*50} \\n')\n",
    "            \n",
    "            self.log('TRAINING...')\n",
    "            train_loss = self.train(mb, model, optimizer, self.device, scheduler)\n",
    "            train_loss_list.append(train_loss) #for graph\n",
    "            self.log(f'Training time: {round(time.time()-start, 2)} secs \\n')\n",
    "            \n",
    "            start = time.time()\n",
    "            self.log('EVALUATING...')\n",
    "            valid_loss = self.validate(mb, model, self.device)    \n",
    "            valid_loss_list.append(valid_loss) #for graph\n",
    "            \n",
    "            if show_graph:\n",
    "                self.plot_loss_update(epoch, epochs, mb, train_loss_list, valid_loss_list) # for graph\n",
    "                               \n",
    "            epoch_end = timeit.default_timer()\n",
    "            total_time = epoch_end - epoch_start\n",
    "            mins, secs = divmod(total_time, 60)\n",
    "            hours, mins = divmod(mins, 60)\n",
    "            ret_time = f'{int(hours)}:{int(mins)}:{int(secs)}'\n",
    "            mb.write([epoch,f'{train_loss:.6f}',f'{valid_loss:.6f}',\n",
    "                      f'{ret_time}'],table=True)\n",
    "            self.log(f'Evaluation time: {ret_time}\\n')\n",
    "#             break\n",
    "            \n",
    "        if return_metric: return best_metric\n",
    "    \n",
    "    def train(self, mb, model, opt, device, sched=None):     \n",
    "        model.train()\n",
    "        train_loss = 0       \n",
    "        for ind, xy in enumerate(progress_bar(self.train_dl, parent=mb)):\n",
    "            xy = {key: xy_.to(device) for key, xy_ in xy.items()}\n",
    "            opt.zero_grad()\n",
    "            loss, *out = model(**xy)\n",
    "            loss.backward()\n",
    "            opt.step()       \n",
    "            if sched is not None:\n",
    "                sched.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            if ind % 500 == 0:\n",
    "                self.log(f'Batch: {ind}, Train loss: {train_loss/ len(self.train_dl)}')\n",
    "            \n",
    "            mb.child.comment = f'{train_loss / (ind+1) :.3f}'\n",
    "        return train_loss / len(self.train_dl)\n",
    "    \n",
    "    def validate(self, mb, model, device):    \n",
    "        model.eval()\n",
    "        valid_loss = 0      \n",
    "        with torch.no_grad():\n",
    "            for ind, xy in enumerate(progress_bar(self.valid_dl, parent=mb)):\n",
    "                xy = {key: xy_.to(device) for key, xy_ in xy.items()}\n",
    "                opt.zero_grad()\n",
    "                loss, *out = model(**xy)\n",
    "                \n",
    "                valid_loss += loss.item()\n",
    "\n",
    "                if ind % 500 == 0:\n",
    "                    self.log(f'Batch: {ind}, Valid loss: {valid_loss / (ind+1) :.3f}')\n",
    "\n",
    "                mb.child.comment = f'{valid_loss / (ind+1) :.3f}'  \n",
    "        return valid_loss / len(self.valid_dl)\n",
    "        \n",
    "            \n",
    "    def log(self, message, verbose=False):\n",
    "        if verbose: print(message)\n",
    "        with open(self.log_file, 'a+') as logger_:\n",
    "            logger_.write(f'{message}\\n')\n",
    "            \n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_loss_update(epoch, epochs, mb, train_loss, valid_loss):\n",
    "        \"\"\" dynamically print the loss plot during the training/validation loop.\n",
    "            expects epoch to start from 1.\n",
    "        \"\"\"\n",
    "        x = range(1, epoch+1)\n",
    "        y = np.concatenate((train_loss, valid_loss))\n",
    "        graphs = [[x,train_loss], [x,valid_loss]]\n",
    "        x_margin = 0.2\n",
    "        y_margin = 0.05\n",
    "        x_bounds = [1-x_margin, epochs+x_margin]\n",
    "        y_bounds = [np.min(y)-y_margin, np.max(y)+y_margin]\n",
    "\n",
    "        mb.update_graph(np.array(graphs), np.array(x_bounds), np.array(y_bounds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
