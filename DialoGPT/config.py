# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/config.ipynb (unless otherwise specified).

__all__ = ['create_path', 'DATA_PATH', 'MODEL_PATH', 'OUTPUT_PATH', 'LR', 'TRAIN_BATCH_SIZE', 'VALID_BATCH_SIZE',
           'NUM_EPOCHS', 'MAX_SEQ_LEN', 'MODEL_NAME', 'DEVICE', 'TOKENIZER']

# Cell
import os
import torch
import transformers
from pathlib import Path

# Cell
def create_path(path):
    if not os.path.exists(path):
        path.mkdir(parents=True, exist_ok=True)
    return path

# Cell
DATA_PATH = create_path(Path('../data'))
MODEL_PATH = create_path(Path('../weights'))
OUTPUT_PATH = create_path(Path('../outputs'))
LR = 1e-05
TRAIN_BATCH_SIZE = 16
VALID_BATCH_SIZE = 16
NUM_EPOCHS = 4
MAX_SEQ_LEN = 124
MODEL_NAME = 'microsoft/DialoGPT-small'
DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
TOKENIZER = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)