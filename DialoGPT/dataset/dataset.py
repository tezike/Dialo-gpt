# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/dataset.dataset.ipynb (unless otherwise specified).

__all__ = ['DialoGPTDataset', 'df', 'DialoGPTModel']

# Cell
import os
import torch
import itertools
import transformers

import pandas as pd
import numpy as np
import DialoGPT.config as config

# Cell
class DialoGPTDataset():
    def __init__(self, df):
        self.df = df

        self.tokenizer = config.TOKENIZER

    def __len__(self):
        return self.df.shape[0]

    def __getitem__(self, i):
        rows = self.df.iloc[i].values

        tokenized_rows = [self.tokenizer.encode(text + self.tokenizer.eos_token,
                               return_tensors='pt').flatten().numpy().tolist()
                                for text in reversed(rows)]
        tokenized_rows = list(itertools.chain.from_iterable(tokenized_rows))
        return {
            'input_ids': torch.tensor(tokenized_rows, dtype=torch.long),
            'labels': torch.tensor(tokenized_rows, dtype=torch.long)
        }

# Cell
df = pd.read_csv(config.DATA_PATH/'cleaned_df_with_contexts.csv')

# Cell
import torch
import torch.nn as nn
import transformers

import DialoGPT.config as config

# Cell
class DialoGPTModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.model = transformers.AutoModelForCausalLM.from_pretrained(config.MODEL_NAME)

    def forward(input_ids, labels):
#         input_ids = past_key_values = (batch_size, sequence_length)
#         NB: The labels are shifted automatically inside the model so labels can be equal to input_ids
        out = self.model(input_ids=input_ids, labels=labels)
        return out